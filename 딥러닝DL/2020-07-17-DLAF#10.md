# 1-0 Intro 

```
인공지능(AI)을 널리 알린 건, 알파고였다. 현 시점에서 인공지능을 논하려면, 
딥러닝을 빼놓을 수 없다. 딥러닝을 이해하기 위해 꼭 필요한 5가지 활성화 함수를 소개한다. 
```

요즘 딥러닝이 뜨거운 감자다. 
핫 포타토! 구글·아마존·페이스북이 현재 가장 주목하는 분야니, 더 이상 무슨 말이 필요할까. 

그런데 딥러닝이 정확히 무슨 역할을 하는지 아는 사람은 드물다. 

```
딥(deep) = 깊다     
러닝(learning) = 학습
깊은 학습..?
```

> 딥러닝 직역인 '**깊은 학습**'에서 무언가 깊이 파고든다는 느낌을 받을 수 있다. 그렇지 않은가?!


우리가 영어 공부를 할 때 각자의 공부 방식이 있다. 
영어 학원에 다니거나, 과외를 시작하거나, 독학하거나, 동영상 강의를 시청할 수도 있다. 
영어를 배우는데 여러 가지 길이 있는 것처럼 딥러닝도 컴퓨터가 공부하는 방법의 하나라고 보면 된다. 
사람만 공부하는 게 아니다. 
컴퓨터도 공부한다.  

컴퓨터 학습에 쓰이는 딥러닝은, 어마어마하게 많은 양의 데이터에서 패턴을 찾아내는 과정이다. 
패턴을 찾아서 뭘 하냐고? 
사람이 기계에 일일이 입력하지 않아도 기계가 알아서 사람처럼 스스로 판단하는 기술을 가르친다. 

우선 사람의 학습은 어떻게 이루어지는지 생각해보자. 
우리 뇌에는 뉴런이라는 신경 세포가 서로 신호를 주고받으면서 정보를 전달한다. 
이 과정을 통해 사람은 학습한다. 
기계는 인공 뉴런인 퍼셉트론으로 비슷하게 학습한다. 
그러니까 인간의 신경세포 = 기계의 퍼셉트론이라고 이해하면 된다. 

여기까지 이해가 됐다면 오늘 주제인 활성화 함수에 대해 이해할 수 있을 것이다.

자, 다시 우리 뇌에 있는 뉴런으로 돌아가 보자. 
뉴런의 구조를 보면 머리, 몸통, 꼬리로 구분할 수 있다. 
뉴런은 머리 쪽에 있는 돌기를 통해 전기신호를 전달받는다. 
각 신호는 이런저런 과정을 통해 가공된 후 몸통 부분을 통해 이동한다. 
꼬리 부분에 도달한 신호들의 총합이 기준치 이상이라면 이웃한 뉴런으로 넘어가고 아니면 넘어가지 않는다.  

인공 뉴런인 퍼셉트론도 비슷한 원리로 작동한다. 
뉴런이 전기 신호를 전달받아 이웃 뉴런에 보내는 것처럼 퍼셉트론도 입력 신호를 받아 출력 신호로 내보낸다. 
그런데 입력 신호가 그대로 출력되는 게 아니라 계산 과정을 거쳐서 출력된다. 
왜 계산 과정을 거쳐야 하는지는 뒷부분에 이어서 설명할 예정.

입력 신호가 출력되기 전에 계산 과정을 거친다고 위에서 설명했다. 
이때 쓰이는 공식이 바로 활성화 함수다. (드디어 여기까지 왔다~~~!)


먼저 수학적 정의를 보자. 
활성화 함수는 입력과 가중치의 곱들의 합에 편향을 더한 값(a)을 받아 출력신호로 변환하는 함수. 
외계어는 아니지만, 쉽게 손에 안 잡힌다. 
조금 더 쉽게 설명해보자면, 아래 식을 참고해보자.

```
입력 신호 x
변수 w
총합 a, a = x1*w1 + x2*w2
활성화 함수 h(), h(a) = z 
출력 신호 z
```

어렴풋이 갈피가 잡히는 느낌이 든다. 그럼 갑자기 튀어나온 변수 w에 대해 해명할 차례이다. 
방 치우기, 컴퓨터 게임하기, 밥 먹기.. 등등 우리는 할 일 들을 각자 우선순위대로 해치운다. 
이때, 우리는 주어진 일들에 중요도를 매겨 차례대로 순서를 정하는데, 마찬가지로 퍼셉트론도 입력된 신호마다 중요도가 부여된다. 
이때 입력된 신호의 중요도를 가중치라고 한다. 가중치는 영어로 weight, 무게라는 뜻을 가지고 있다. 

위의 식에서 총합에 대해 말했다. 
입력 신호와 각 신호에 따른 가중치를 각각 곱한 뒤, (입력 신호x가중치)들을 모두 더한 총합을 의미한다. 
이제 이 총합이 계산 과정을 거쳐 드디어 출력된다.
바로 여기! 활성화 함수가 바로 이 총합이 거치는 계산 과정이다!!!


마치 요리랑 비슷하다. 
카레를 만들 때 냄비가 없다면 아무리 당근, 고구마, 호박, 버섯, 카레 가루 등등 재료들이 준비되어 있어도 아무것도 할 수 없는 것과 비슷한 맥락이다. 
여기서 입력 신호는 당근, 고구마이고 냄비가 활성화 함수, 완성된 카레가 출력 신호이다. 

그런데 활성화 함수는 도대체 왜 쓰는 걸까? 앞부분에 우리 뇌의 뉴런이 전기 신호를 전달하는 방법에 관해 설명했다. 
해당 뉴런에 전달된 신호들의 총합이 기준치 이상이어야 이웃 뉴런에 신호를 전달된다. 
딥러닝 네트워크에서 신호 흐름을 파악하여 각 퍼셉트론에 제한을 걸어둔 것이 활성화 함수이다. 
활성화 함수에서 적용한 공식의 기준을 만족하는 경우에만 다음 퍼셉트론으로 신호가 이어가는 것이다.

간단한 예제를 소개해보겠다. 


위 그래프를 보면 x = 0을 기준으로 x가 0보다 작으면 0을, 0보다 크면 1을 출력한다.
이 활성화 함수의 기준치는 0이다. 퍼셉트론에 계단 함수가 쓰였을 때 1이 출력되면 '활성'되고 0이 출력되면 '비활성' 된다. 
생각보다 간단하다.   

지금까지 기본적으로 활성화 함수의 정체와 필요성에 대해 살펴보았다. 다음 글부터는 가장 많이 쓰이는 5가지 모델에 대해 다룰 예정이다. 
